{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN classification\n",
    "\n",
    "This code has been developed starting from the the online [Pytorch Full Course video](https://www.youtube.com/watch?v=V_xro1bcAuA&t=53736s). This is done for making some practice in developing models from scratch using `torch` and `torchvision` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "For the example we'll use the `FashionMNIST` dataset directly available in `torchvision.datasets`.\n",
    "\n",
    "### Load and visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download = True if os.path.exists('Datasets/FashionMNIST') else False\n",
    "\n",
    "# Load the training and testing dataset\n",
    "train_dataset = datasets.FashionMNIST(download=True, root='Datasets', target_transform=None, transform=ToTensor(), train=True)\n",
    "test_dataset = datasets.FashionMNIST(download=True, root='Datasets', target_transform=None, transform=ToTensor(), train=False)\n",
    "\n",
    "# Print dataset infos\n",
    "print(f'Dataset Infos:\\n\\n{train_dataset}\\n\\n{test_dataset}')\n",
    "print(f'\\nClasses: {train_dataset.class_to_idx}')\n",
    "print(f'\\nData shape ((CxHxW), class), e.g. ({train_dataset[0][0].shape}, {train_dataset[0][1]})')\n",
    "\n",
    "# Print some examples\n",
    "fig = plt.figure(figsize=(9,9))\n",
    "rows, cols = 4,4\n",
    "for i in range(1, rows*cols+1):\n",
    "    index = randint(0, len(train_dataset))\n",
    "    img, label = train_dataset[index]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "    plt.title(train_dataset.classes[label])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataLoader\n",
    "The dataloader is a python iterable, in this case we want to turn create batches of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "\n",
    "with open('./configs.yml', 'r') as f:\n",
    "    configs = yaml.safe_load(f)\n",
    "    f.close()\n",
    "\n",
    "print(f'Loaded configuration from configs.yml:\\n{configs}')\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=configs['batch_size'], shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=configs['batch_size'], shuffle=False, num_workers=2)\n",
    "\n",
    "imgs_batch_example, labels_batch_example = next(iter(train_dataloader))\n",
    "print(f'\\nBatches shape (img_batches, labels_batches): ({imgs_batch_example.shape}, {labels_batch_example.shape})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model\n",
    "\n",
    "All the model implementations are available at `models.py` file. We will start from a linear and non-linear model, the we'll develop CNN-based models to compare the results.\n",
    "\n",
    "### Import the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import FashionModelLinear\n",
    "\n",
    "output_shape = len(train_dataset.classes)\n",
    "channels, width, heigth = (imgs_batch_example.shape[1], imgs_batch_example.shape[2], imgs_batch_example.shape[3])\n",
    "device = configs['device']\n",
    "\n",
    "model_v0 = FashionModelLinear(img_width=width, img_height=heigth, hidden_units=configs['hidden_units'], output_shape=output_shape).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the loss, optimizer and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_v0.parameters(), lr=configs['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a training and testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from evaluation import get_accuracy\n",
    "\n",
    "def evaluate_model(model: torch.nn.Module,\n",
    "                   loss_fn: torch.nn.Module,\n",
    "                   test_dataloader: torch.utils.data.DataLoader,\n",
    "                   device: str):\n",
    "    \"\"\"\n",
    "    Evaluates the model's performance on a test dataset.\n",
    "\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The neural network model to be evaluated.\n",
    "        loss_fn (torch.nn.Module): The loss function used to compute the model's loss.\n",
    "        test_dataloader (torch.utils.data.DataLoader): The DataLoader for the test dataset.\n",
    "        device (str): The device to perform the evaluation on ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the model name, average loss, and accuracy on the test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    test_loss, test_acc = 0.0, 0.0\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.inference_mode():  # Disable gradient computation for inference\n",
    "\n",
    "        for images, labels in test_dataloader:\n",
    "            # Move data to the correct device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass: compute predictions\n",
    "            predictions = model(images) \n",
    "            \n",
    "            # Loss and accuracy calculation\n",
    "            test_loss += loss_fn(predictions, labels)\n",
    "            test_acc += get_accuracy(labels, predictions.argmax(dim=1))\n",
    "\n",
    "        # Calculate the average loss and accuracy\n",
    "        test_loss = test_loss / len(test_dataloader)\n",
    "        test_acc = test_acc / len(test_dataloader)\n",
    "\n",
    "        return {\n",
    "            \"model_name\": model.__class__.__name__,\n",
    "            \"model_test_loss\": test_loss.to('cpu').item(),\n",
    "            \"model_test_accuracy\": test_acc\n",
    "        }\n",
    "    \n",
    "\n",
    "\n",
    "def train_model(model: torch.nn.Module, \n",
    "                loss_fn: torch.nn.Module,\n",
    "                train_dataloader: torch.utils.data.DataLoader,\n",
    "                device: str,\n",
    "                epochs: int,\n",
    "                optimizer: torch.optim.Optimizer):\n",
    "    \"\"\"\n",
    "    Trains a PyTorch model over a specified number of epochs and evaluates it at the end of each epoch.\n",
    "\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The neural network model to train.\n",
    "        loss_fn (torch.nn.Module): The loss function used to compute the loss during training.\n",
    "        train_dataloader (torch.utils.data.DataLoader): DataLoader for the training data.\n",
    "        device (str): The device to use for training (e.g., 'cpu' or 'cuda').\n",
    "        epochs (int): The number of epochs to train the model.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer used for updating the model parameters.\n",
    "    \n",
    "    Returns:\n",
    "        None: The function prints out the training loss and evaluation metrics at the end of each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate total number of batches (epochs * batches per epoch)\n",
    "    total_batches = epochs * len(train_dataloader)\n",
    "\n",
    "    epochs_test_results = []\n",
    "    \n",
    "    # Initialize a single tqdm progress bar for all batches\n",
    "    progress_bar = tqdm(total=total_batches, desc=\"Training Progress\", position=0, leave=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_dataloader):\n",
    "            model.train()\n",
    "            \n",
    "            # Move data to the correct device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(images)\n",
    "            \n",
    "            # Loss calculation\n",
    "            loss = loss_fn(predictions, labels)\n",
    "            train_loss += loss.item()  # accumulate the loss for this batch\n",
    "\n",
    "            # Optimizer zero grad\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimizer optimization \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update the progress bar\n",
    "            progress_bar.update(1)\n",
    "        \n",
    "        # Adjust the training loss by averaging over the number of batches\n",
    "        train_loss = train_loss / len(train_dataloader)\n",
    "        \n",
    "        # Testing and evaluation\n",
    "        test_results = evaluate_model(model, loss_fn, test_dataloader, device)\n",
    "        test_results['epoch'] = epoch\n",
    "        epochs_test_results.append(test_results)\n",
    "\n",
    "    for res in epochs_test_results:\n",
    "        print(f\"\\n\\nResults for epoch {res['epoch']}\")\n",
    "        print(f\"Test Accuracy: {res['model_test_accuracy']:.4f}%   Test Loss: {res['model_test_loss']:.4f}\")\n",
    "    \n",
    "    # Close the progress bar once training is complete\n",
    "    progress_bar.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model=model_v0,\n",
    "            loss_fn=loss_fn,\n",
    "            train_dataloader=train_dataloader,\n",
    "            device=device,\n",
    "            epochs=configs['epochs'],\n",
    "            optimizer=optimizer)\n",
    "\n",
    "model_v0 = model_v0.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a non-linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import FashionModelNonLinear\n",
    "\n",
    "model_v1 = FashionModelNonLinear(img_width=width, img_height=heigth, hidden_units=configs['hidden_units'], output_shape=len(train_dataset.classes)).to(device)\n",
    "optimizer = torch.optim.SGD(model_v1.parameters(), lr=configs['lr'])\n",
    "train_model(model=model_v1,\n",
    "            loss_fn=loss_fn,\n",
    "            train_dataloader=train_dataloader,\n",
    "            device=device,\n",
    "            epochs=configs['epochs'],\n",
    "            optimizer=optimizer)\n",
    "\n",
    "model_v1 = model_v1.to('cpu') # Move the model to the CPU to free the GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the two models results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import get_confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "confusion_matrix = None\n",
    "with torch.inference_mode():\n",
    "    model_v0 = model_v0.to(device) # Move the model into the GPU\n",
    "    model_v0.eval()\n",
    "    for images, labels in test_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device) # Move the data into the GPU\n",
    "        predictions = model_v0(images) # Forward step\n",
    "        predictions = predictions.argmax(dim=1) # Get the class with highest probability score\n",
    "        \n",
    "        confusion_matrix = get_confusion_matrix(y_pred=predictions, y_true=labels, classes=len(train_dataset.classes), confusion_matrix=confusion_matrix)\n",
    "\n",
    "    # Plot the final confusion matrix\n",
    "    plot_confusion_matrix(confusion_matrix=confusion_matrix,\n",
    "                          class_names=train_dataset.classes,\n",
    "                          title='Confusion matrix model V0') \n",
    "\n",
    "model_v0 = model_v0.to('cpu') # Move the model to the CPU to free the GPU memory\n",
    "\n",
    "confusion_matrix = None\n",
    "with torch.inference_mode():\n",
    "    model_v1 = model_v1.to(device) # Move the model into the GPU\n",
    "    model_v1.eval()\n",
    "    for images, labels in test_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        predictions = model_v1(images) # Forward step\n",
    "        predictions = predictions.argmax(dim=1) # Get the class with highest probability score\n",
    "\n",
    "        confusion_matrix = get_confusion_matrix(y_pred=predictions, y_true=labels, classes=len(train_dataset.classes), confusion_matrix=confusion_matrix)\n",
    "\n",
    "\n",
    "    plot_confusion_matrix(confusion_matrix=confusion_matrix,\n",
    "                          class_names=train_dataset.classes,\n",
    "                          title='Confusion matrix model V1')\n",
    "    \n",
    "model_v1 = model_v1.to('cpu') # Move the model to the CPU to free the GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start dealing with CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import FashionModelCnnV0\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "cnn_model_v0 = FashionModelCnnV0(img_channels=channels,\n",
    "                              hidden_units=configs['hidden_units'],\n",
    "                              output_shape=len(train_dataset.classes)).to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(cnn_model_v0.parameters(), lr=configs['lr'])\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "train_model(model=cnn_model_v0,\n",
    "            loss_fn=loss_fn,\n",
    "            train_dataloader=train_dataloader,\n",
    "            device=device,\n",
    "            epochs=configs['epochs'],\n",
    "            optimizer=optimizer)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    cnn_model_v0.eval()\n",
    "    confusion_matrix = None\n",
    "    for images, labels in test_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        predictions = cnn_model_v0(images)\n",
    "        predictions = predictions.argmax(dim=1) # Get the class with highest probability score\n",
    "        confusion_matrix = get_confusion_matrix(labels, predictions, len(train_dataset.classes), confusion_matrix)\n",
    "    \n",
    "    plot_confusion_matrix(confusion_matrix=confusion_matrix,\n",
    "                          class_names=train_dataset.classes,\n",
    "                          title='Confusion matrix CNN model V0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "models_dir_path = Path(configs['models_dir'])\n",
    "models_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "model_name = 'cnn_model_v0.pth'\n",
    "\n",
    "print(f'Saving model to {models_dir_path / model_name}')\n",
    "cnn_model_v0.to('cpu')\n",
    "torch.save(cnn_model_v0.state_dict(), models_dir_path / model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a classification task over a custom dataset\n",
    "\n",
    "## Preliminary operations on the dataset\n",
    "The dataset I will use for this part can be retrieved on Kaggle at the following [link](https://www.kaggle.com/datasets/puneet6060/intel-image-classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from random import randint\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Check if the dataset exists\n",
    "if not os.path.exists('Datasets/IntelImageClassification/'):\n",
    "    print('ERROR! Dataset not found')\n",
    "    exit()\n",
    "\n",
    "test_folder = 'Datasets/IntelImageClassification/test'\n",
    "train_folder = 'Datasets/IntelImageClassification/train'\n",
    "\n",
    "train_imgs = [img for img in glob(f'{train_folder}/*/*')]\n",
    "test_imgs = [img for img in glob(f'{test_folder}/*/*')]\n",
    "\n",
    "classes = os.listdir(train_folder)\n",
    "print(f'Classes found in the dataset:\\n{classes}')\n",
    "\n",
    "# Number of images to display\n",
    "num_images = 3\n",
    "\n",
    "# Create a figure with a row of subplots\n",
    "fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
    "\n",
    "# Loop to display the images\n",
    "for i in range(num_images):\n",
    "    index = randint(0, len(train_imgs))\n",
    "    img = Image.open(train_imgs[index])\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis('off')  # Hide axes\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a torchvision dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor, Resize, RandomVerticalFlip, RandomRotation, RandomHorizontalFlip\n",
    "from torchvision import datasets\n",
    "\n",
    "import yaml\n",
    "\n",
    "dataset_transforms = transforms.Compose([\n",
    "    Resize(size=(128, 128)),\n",
    "    RandomHorizontalFlip(),\n",
    "    RandomVerticalFlip(),\n",
    "    RandomRotation(degrees=45),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root='Datasets/IntelImageClassification/train', transform=dataset_transforms, target_transform=None)\n",
    "test_dataset = datasets.ImageFolder(root='Datasets/IntelImageClassification/test', transform=dataset_transforms, target_transform=None)\n",
    "\n",
    "print(f'Dataset fully loaded!')\n",
    "\n",
    "with open('configs.yml', 'r') as f:\n",
    "    configs = yaml.safe_load(f)\n",
    "    f.close()\n",
    "\n",
    "# Create the two dataloaders\n",
    "train_dataloader = DataLoader(dataset=train_dataset, \n",
    "                              batch_size=configs['batch_size'],\n",
    "                              num_workers=2,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset, \n",
    "                              batch_size=configs['batch_size'],\n",
    "                              num_workers=2,\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import IntelClassificationV0\n",
    "from torch import nn\n",
    "\n",
    "device = configs['device']\n",
    "\n",
    "images, labels = next(iter(train_dataloader))\n",
    "channels, width, heigth = images.shape[1:]\n",
    "print(f'Image shape: {images.shape[1:]}\\nBatch shape: {images.shape}')\n",
    "model = IntelClassificationV0(img_channels=channels, \n",
    "                              hidden_units=configs['hidden_units'],\n",
    "                              output_shape=len(train_dataset.classes)).to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=configs['lr'])\n",
    "loss_fn =  nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import train_model\n",
    "\n",
    "train_model(model=model,\n",
    "            epochs=configs['epochs'],\n",
    "            train_dataloader=train_dataloader,\n",
    "            test_dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
